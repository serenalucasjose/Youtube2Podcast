# ğŸ”¬ AnÃ¡lisis de OptimizaciÃ³n para Raspberry Pi 4

## Youtube2Podcast - Reporte de Performance

**Fecha:** Noviembre 2025  
**VersiÃ³n analizada:** 1.5.0  
**Hardware objetivo:** Raspberry Pi 4 (ARMv8, 4 cores, 8GB RAM)

---

## ğŸ“‹ Resumen Ejecutivo

| CategorÃ­a | CrÃ­ticos (P1) | Importantes (P2) | Opcionales (P3) |
|-----------|:-------------:|:----------------:|:---------------:|
| CPU | 4 | 5 | 3 |
| RAM | 3 | 4 | 2 |
| I/O | 2 | 4 | 2 |
| Bandwidth | 1 | 3 | 2 |
| RPi4 EspecÃ­fico | 2 | 3 | 2 |
| **Total** | **12** | **19** | **11** |

### Arquitectura Actual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Node.js (Express)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Routes  â”‚  â”‚   SSE   â”‚  â”‚Sessions â”‚  â”‚  Static Files   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â”‚            â”‚            â”‚                â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                    SQLite (better-sqlite3)          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ spawn()
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   process_translation   â”‚ â”‚  process_transcription  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ faster-whisper  â”‚   â”‚ â”‚   â”‚ faster-whisper  â”‚   â”‚
â”‚   â”‚ (torch + model) â”‚   â”‚ â”‚   â”‚ (torch + model) â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  transformers   â”‚   â”‚ â”‚   â”‚     fpdf2       â”‚   â”‚
â”‚   â”‚ (Helsinki-NLP)  â”‚   â”‚ â”‚   â”‚  (PDF output)   â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚                         â”‚
â”‚   â”‚    edge-tts     â”‚   â”‚ â”‚                         â”‚
â”‚   â”‚ (pydub convert) â”‚   â”‚ â”‚                         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”´ 1. USO DE CPU

### P1-CPU-01: bcrypt.compareSync() bloquea el Event Loop

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/index.js:82` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸŸ¢ Bajo (5 min) |

**Problema:**  
`bcrypt.compareSync()` es una operaciÃ³n CPU-bound que bloquea el event loop de Node.js durante ~100-200ms en ARM.

**CÃ³digo actual:**
```javascript
if (user && bcrypt.compareSync(password, user.password_hash)) {
```

**Impacto:**  
- Todas las requests HTTP quedan en espera mientras se verifica el password
- Con mÃºltiples logins simultÃ¡neos, el servidor se vuelve irresponsivo

**SoluciÃ³n:**
```javascript
// Cambiar a versiÃ³n async
app.post('/login', async (req, res) => {
    const { username, password } = req.body;
    const user = db.getUserByUsername(username);
    
    if (user && await bcrypt.compare(password, user.password_hash)) {
        // ...
    }
});
```

---

### P1-CPU-02: Modelo de IA re-instanciado en cada procesamiento

| Campo | Valor |
|-------|-------|
| **Archivos** | `scripts/process_transcription.py:76-79`, `scripts/process_translation.py:39-42` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸ”´ Alto (1-2 dÃ­as) |

**Problema:**  
`WhisperModel("tiny")` y `pipeline("translation")` se cargan desde disco **cada vez** que se procesa un audio.

**CÃ³digo actual:**
```python
def transcribe_audio(audio_path: str) -> str:
    # Se ejecuta CADA VEZ
    from faster_whisper import WhisperModel
    model = WhisperModel("tiny", device="cpu", compute_type="int8")
    # ...
    del model  # Se destruye al final
```

**Impacto:**
- Tiempo de carga de modelos: ~15-30 segundos en RPi4
- Tiempo total de procesamiento ~3x mayor del necesario
- Uso excesivo de I/O de disco

**SoluciÃ³n: Implementar Worker Python Persistente**

```python
#!/usr/bin/env python3
# scripts/worker_ai.py - Worker persistente para modelos de IA

import sys
import json
from faster_whisper import WhisperModel
from transformers import pipeline

# ============================================
# CARGAR MODELOS UNA SOLA VEZ AL INICIAR
# ============================================
print(json.dumps({"status": "loading", "message": "Cargando modelos..."}), flush=True)

whisper_model = WhisperModel("tiny", device="cpu", compute_type="int8")
translator = pipeline("translation", model="Helsinki-NLP/opus-mt-en-es", device=-1)

print(json.dumps({"status": "ready", "message": "Modelos cargados"}), flush=True)

# ============================================
# LOOP DE PROCESAMIENTO VIA STDIN
# ============================================
for line in sys.stdin:
    try:
        job = json.loads(line.strip())
        job_type = job.get("type")
        
        if job_type == "transcribe":
            # Usar whisper_model ya cargado
            segments, _ = whisper_model.transcribe(job["input_path"], ...)
            result = {"success": True, "segments": [...]}
            
        elif job_type == "translate":
            # Usar translator ya cargado
            translated = translator(job["text"])
            result = {"success": True, "text": translated}
            
        print(json.dumps(result), flush=True)
        
    except Exception as e:
        print(json.dumps({"success": False, "error": str(e)}), flush=True)
```

**Cambios en Node.js:**
```javascript
// src/ai_worker.js - Manager del worker Python
const { spawn } = require('child_process');

class AIWorkerManager {
    constructor() {
        this.worker = null;
        this.queue = [];
        this.isProcessing = false;
    }
    
    async initialize() {
        this.worker = spawn('python3', ['scripts/worker_ai.py']);
        // Esperar mensaje "ready"
        await this.waitForReady();
    }
    
    async process(job) {
        return new Promise((resolve, reject) => {
            this.worker.stdin.write(JSON.stringify(job) + '\n');
            // Manejar respuesta...
        });
    }
}

module.exports = new AIWorkerManager();
```

---

### P1-CPU-03: Polling cada 5 segundos consume CPU innecesariamente

| Campo | Valor |
|-------|-------|
| **Archivo** | `views/index.ejs:961` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸŸ¢ Bajo (15 min) |

**Problema:**  
`setInterval(pollTaskStatus, 5000)` hace requests constantes incluso cuando no hay tareas activas.

**CÃ³digo actual:**
```javascript
setInterval(pollTaskStatus, 5000);
setTimeout(pollTaskStatus, 2000);
```

**Impacto:**
- Request HTTP cada 5 segundos por cliente conectado
- CPU y red ocupados innecesariamente
- Con 10 clientes = 120 requests/minuto sin tareas activas

**SoluciÃ³n:**
```javascript
let pollingInterval = null;

function startPollingIfNeeded() {
    const ids = getProcessingEpisodeIds();
    
    if (ids.length > 0 && !pollingInterval) {
        // Solo iniciar polling si hay tareas
        pollingInterval = setInterval(pollTaskStatus, 5000);
    } else if (ids.length === 0 && pollingInterval) {
        // Detener si no hay tareas
        clearInterval(pollingInterval);
        pollingInterval = null;
    }
}

// Llamar despuÃ©s de cada actualizaciÃ³n de estado
function handleSSEMessage(event) {
    // ... procesar mensaje ...
    startPollingIfNeeded();
}

// Inicializar una vez
document.addEventListener('DOMContentLoaded', () => {
    startPollingIfNeeded();
});
```

---

### P1-CPU-04: bcrypt.hashSync() en seed de usuarios bloquea startup

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/db.js:86` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸŸ¢ Bajo (10 min) |

**Problema:**  
4 llamadas a `bcrypt.hashSync()` durante el startup, cada una ~200ms en ARM = ~800ms de bloqueo.

**CÃ³digo actual:**
```javascript
usersToCreate.forEach(u => {
    if (!checkStmt.get(u.username)) {
        const hash = bcrypt.hashSync(u.password, 10);  // BLOQUEA
        insertStmt.run(u.username, hash, u.role);
    }
});
```

**SoluciÃ³n: Usar hashes pre-calculados para usuarios seed**
```javascript
const seedUsers = () => {
    // Hashes pre-calculados (bcrypt cost=10)
    const usersToCreate = [
        { 
            username: 'admin', 
            password_hash: '$2a$10$N9qo8uLOickgx2ZMRZoMy...',  // "admin"
            role: 'admin' 
        },
        // ...
    ];

    const insertStmt = db.prepare(
        'INSERT INTO users (username, password_hash, role) VALUES (?, ?, ?)'
    );
    
    usersToCreate.forEach(u => {
        if (!checkStmt.get(u.username)) {
            insertStmt.run(u.username, u.password_hash, u.role);
        }
    });
};
```

---

### P2-CPU-05: CÃ¡lculo de disk usage sÃ­ncrono en Admin

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/index.js:471-481` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¡ Medio (30 min) |

**Problema:**  
`fs.readdirSync()` + `fs.statSync()` en loop bloquea mientras calcula tamaÃ±o de archivos.

**CÃ³digo actual:**
```javascript
const files = fs.readdirSync(downloadsDir);
for (const file of files) {
    const stat = fs.statSync(filePath);
    if (stat.isFile()) {
        diskUsage += stat.size;
    }
}
```

**SoluciÃ³n:**
```javascript
// VersiÃ³n async no bloqueante
async function calculateDiskUsage(dir) {
    try {
        const files = await fs.promises.readdir(dir);
        const stats = await Promise.all(
            files.map(async (file) => {
                const filePath = path.join(dir, file);
                try {
                    const stat = await fs.promises.stat(filePath);
                    return stat.isFile() ? stat.size : 0;
                } catch {
                    return 0;
                }
            })
        );
        return stats.reduce((sum, size) => sum + size, 0);
    } catch {
        return 0;
    }
}

// En la ruta /admin
app.get('/admin', requireAdmin, async (req, res) => {
    const diskUsage = await calculateDiskUsage(downloadsDir);
    // ...
});
```

---

### P2-CPU-06: Segmentos de Whisper cargados completamente en memoria

| Campo | Valor |
|-------|-------|
| **Archivos** | `scripts/process_transcription.py:95-96`, `scripts/process_translation.py:57-58` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (10 min) |

**Problema:**  
`list(segments)` fuerza a cargar todos los segmentos antes de iterar.

**CÃ³digo actual:**
```python
segment_list = list(segments)  # CARGA TODO EN RAM
total_segments = len(segment_list)

for i, segment in enumerate(segment_list):
    # ...
```

**Impacto:**
- Para audios de 1 hora: ~2000 segmentos en memoria
- Delay inicial mientras se procesa todo
- Pico de memoria innecesario

**SoluciÃ³n: Streaming de segmentos**
```python
# Procesar en streaming, sin cargar todo
segments_data = []
full_text = ""
segment_count = 0

for segment in segments:  # Generator, no list
    segment_count += 1
    full_text += segment.text + " "
    segments_data.append({
        "start": segment.start,
        "end": segment.end,
        "text": segment.text.strip()
    })
    
    # Reportar progreso cada 10 segmentos
    if segment_count % 10 == 0:
        log_progress("stt", 20 + min(50, segment_count // 2), 
                     f"Procesando segmento {segment_count}...")
```

---

### P2-CPU-07: TraducciÃ³n chunk-by-chunk sin batching

| Campo | Valor |
|-------|-------|
| **Archivo** | `scripts/process_translation.py:112-117` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (10 min) |

**Problema:**  
Se traduce chunk por chunk en loop secuencial.

**CÃ³digo actual:**
```python
for i, chunk in enumerate(chunks):
    if chunk:
        result = translator(chunk, max_length=512)  # UNO A LA VEZ
        translated_chunks.append(result[0]["translation_text"])
```

**SoluciÃ³n: Batch translation**
```python
# Filtrar chunks vacÃ­os
valid_chunks = [c for c in chunks if c.strip()]

# Traducir en batch (mucho mÃ¡s eficiente)
if valid_chunks:
    results = translator(valid_chunks, max_length=512, batch_size=4)
    translated_chunks = [r["translation_text"] for r in results]
```

---

### P2-CPU-08: Doble syscall para validar archivo

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/downloader.js:222-230` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (5 min) |

**CÃ³digo actual:**
```javascript
if (!fs.existsSync(finalPath)) {
    throw new Error('Output file was not created');
}
const stats = fs.statSync(finalPath);
if (stats.size < 1000) {
    throw new Error('Output file appears to be corrupted');
}
```

**SoluciÃ³n:**
```javascript
try {
    const stats = fs.statSync(finalPath);
    if (stats.size < 1000) {
        throw new Error('Output file appears to be corrupted (too small)');
    }
} catch (err) {
    if (err.code === 'ENOENT') {
        throw new Error('Output file was not created');
    }
    throw err;
}
```

---

### P2-CPU-09: JSON.parse en cada lÃ­nea de stdout sin validaciÃ³n

| Campo | Valor |
|-------|-------|
| **Archivos** | `src/transcription_service.js:229`, `src/translation_service.js:203` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (5 min) |

**CÃ³digo actual:**
```javascript
for (const line of lines) {
    try {
        const progress = JSON.parse(line);  // Puede fallar frecuentemente
        // ...
    } catch (e) {
        // Log como texto normal
    }
}
```

**SoluciÃ³n: Pre-validar antes de parsear**
```javascript
for (const line of lines) {
    // Solo intentar parsear si parece JSON
    if (line.startsWith('{') && line.endsWith('}')) {
        try {
            const progress = JSON.parse(line);
            // ...
        } catch (e) {
            addLog(episode.id, line, 'info');
        }
    } else {
        addLog(episode.id, line, 'info');
    }
}
```

---

### P3-CPU-10: Heartbeat SSE cada 30 segundos podrÃ­a ser 60

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/index.js:165-176` |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¢ Bajo (1 min) |

**Cambio simple:**
```javascript
// De 30000 a 60000
heartbeatInterval = setInterval(() => {
    // ...
}, 60000);
```

---

### P3-CPU-11: MÃºltiples Date objects creados en addLog()

| Campo | Valor |
|-------|-------|
| **Archivos** | `src/transcription_service.js:77-86`, `src/translation_service.js:60-65` |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¢ Bajo (2 min) |

**CÃ³digo actual:**
```javascript
logEntry.logs.push({
    timestamp: new Date().toISOString(),
    message,
    type
});
logEntry.lastUpdate = new Date();  // Segundo Date object
```

**SoluciÃ³n:**
```javascript
const now = new Date();
logEntry.logs.push({
    timestamp: now.toISOString(),
    message,
    type
});
logEntry.lastUpdate = now;
```

---

### P3-CPU-12: Consultas SQL redundantes en getAdminStats()

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/db.js:247-329` |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¡ Medio (30 min) |

**Problema:**  
6+ queries separadas que podrÃ­an combinarse con CTEs.

**SoluciÃ³n: Query optimizada con CTE**
```sql
WITH stats AS (
    SELECT 
        COUNT(*) as total_episodes,
        SUM(CASE WHEN status = 'ready' THEN 1 ELSE 0 END) as ready_count,
        SUM(CASE WHEN status = 'error' THEN 1 ELSE 0 END) as error_count,
        SUM(CASE WHEN status = 'processing' THEN 1 ELSE 0 END) as processing_count
    FROM episodes
)
SELECT 
    s.*,
    (SELECT COUNT(*) FROM users) as total_users
FROM stats s;
```

---

## ğŸŸ¡ 2. USO DE RAM

### P1-RAM-01: Modelos de IA consumen ~2-3GB RAM en cada proceso

| Campo | Valor |
|-------|-------|
| **Archivos** | `scripts/process_translation.py`, `scripts/process_transcription.py` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸ”´ Alto (relacionado con P1-CPU-02) |

**Desglose de memoria por proceso:**

| Componente | RAM Aproximada |
|------------|----------------|
| Python interpreter | ~50MB |
| PyTorch | ~500MB |
| faster-whisper (tiny) | ~200MB |
| transformers + modelo | ~800MB |
| Buffers de audio | ~200MB |
| **Total por proceso** | **~1.7GB** |

**Impacto:**
- Con transcripciÃ³n + traducciÃ³n simultÃ¡nea: ~3.4GB
- Sistema base + Node.js: ~500MB
- **Total**: ~4GB, dejando 4GB para swap/cache
- Si hay mÃ¡s procesos: OOM kills

**SoluciÃ³n:**
1. Implementar worker Ãºnico persistente (ver P1-CPU-02)
2. Agregar mutex para serializar trabajos de IA:

```javascript
// src/ai_mutex.js
class AIMutex {
    constructor() {
        this.locked = false;
        this.queue = [];
    }
    
    async acquire() {
        if (!this.locked) {
            this.locked = true;
            return;
        }
        
        return new Promise(resolve => {
            this.queue.push(resolve);
        });
    }
    
    release() {
        if (this.queue.length > 0) {
            const next = this.queue.shift();
            next();
        } else {
            this.locked = false;
        }
    }
}

module.exports = new AIMutex();
```

---

### P1-RAM-02: Buffer de logs sin lÃ­mite global

| Campo | Valor |
|-------|-------|
| **Archivos** | `src/transcription_service.js:29-30`, `src/translation_service.js:30` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸŸ¢ Bajo (15 min) |

**Problema:**  
`activeLogs = new Map()` sin lÃ­mite de episodios acumula logs indefinidamente.

**CÃ³digo actual:**
```javascript
const activeLogs = new Map();
const MAX_LOGS_PER_EPISODE = 100;

function addLog(episodeId, message, type = 'info') {
    if (!activeLogs.has(episodeId)) {
        activeLogs.set(episodeId, { logs: [], lastUpdate: new Date() });
    }
    // ... agrega log sin verificar cantidad total de episodios
}
```

**SoluciÃ³n: Agregar lÃ­mite global**
```javascript
const activeLogs = new Map();
const MAX_LOGS_PER_EPISODE = 100;
const MAX_ACTIVE_EPISODES = 20;  // Nuevo lÃ­mite

function addLog(episodeId, message, type = 'info') {
    // Limpiar episodios antiguos si excedemos el lÃ­mite
    if (!activeLogs.has(episodeId) && activeLogs.size >= MAX_ACTIVE_EPISODES) {
        // Eliminar el episodio con lastUpdate mÃ¡s antiguo
        let oldestId = null;
        let oldestTime = Infinity;
        
        for (const [id, entry] of activeLogs.entries()) {
            if (entry.lastUpdate.getTime() < oldestTime) {
                oldestTime = entry.lastUpdate.getTime();
                oldestId = id;
            }
        }
        
        if (oldestId) {
            activeLogs.delete(oldestId);
        }
    }
    
    // ... resto del cÃ³digo igual
}
```

---

### P1-RAM-03: getEpisodes() sin paginaciÃ³n en Admin

| Campo | Valor |
|-------|-------|
| **Archivos** | `src/db.js:168-179`, `src/index.js:464` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸŸ¡ Medio (1 hora) |

**CÃ³digo actual:**
```javascript
getEpisodes: (userId = null) => {
    if (userId) {
        return db.prepare('SELECT * FROM episodes WHERE user_id = ? ORDER BY created_at DESC').all(userId);
    }
    // Sin LIMIT - carga TODOS
    return db.prepare(`
        SELECT e.*, u.username as owner_username 
        FROM episodes e 
        LEFT JOIN users u ON e.user_id = u.id 
        ORDER BY e.created_at DESC
    `).all();
}
```

**SoluciÃ³n:**
```javascript
getEpisodes: (userId = null, { limit = 50, offset = 0 } = {}) => {
    if (userId) {
        return db.prepare(`
            SELECT * FROM episodes 
            WHERE user_id = ? 
            ORDER BY created_at DESC 
            LIMIT ? OFFSET ?
        `).all(userId, limit, offset);
    }
    
    return db.prepare(`
        SELECT e.*, u.username as owner_username 
        FROM episodes e 
        LEFT JOIN users u ON e.user_id = u.id 
        ORDER BY e.created_at DESC
        LIMIT ? OFFSET ?
    `).all(limit, offset);
},

getEpisodesCount: (userId = null) => {
    if (userId) {
        return db.prepare('SELECT COUNT(*) as count FROM episodes WHERE user_id = ?').get(userId).count;
    }
    return db.prepare('SELECT COUNT(*) as count FROM episodes').get().count;
}
```

---

### P2-RAM-04: EventEmitter con maxListeners=50

| Campo | Valor |
|-------|-------|
| **Archivos** | `src/downloader.js:29`, `src/transcription_service.js:22`, `src/translation_service.js:21` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¡ Medio (2 horas) |

**Problema:**  
3 EventEmitters separados, cada uno con 50 listeners mÃ¡ximo.

**SoluciÃ³n: Consolidar en un Ãºnico EventEmitter global**
```javascript
// src/events.js - Nuevo archivo
const EventEmitter = require('events');

class AppEventEmitter extends EventEmitter {
    constructor() {
        super();
        this.setMaxListeners(100);
    }
    
    emitProgress(type, data) {
        this.emit('progress', { type, ...data });
    }
    
    emitDownloadProgress(data) {
        this.emitProgress('download', data);
    }
    
    emitTranslationProgress(data) {
        this.emitProgress('translation', data);
    }
    
    emitTranscriptionProgress(data) {
        this.emitProgress('transcription', data);
    }
}

module.exports = new AppEventEmitter();
```

---

### P2-RAM-05: webPush configurado 3 veces

| Campo | Valor |
|-------|-------|
| **Archivos** | `src/index.js:14-21`, `src/downloader.js:8-18`, `src/transcription_service.js:8-18`, `src/translation_service.js:8-18` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (20 min) |

**SoluciÃ³n: MÃ³dulo centralizado**
```javascript
// src/push.js - Nuevo archivo
const webPush = require('web-push');

let configured = false;

function configure() {
    if (configured) return;
    
    if (process.env.VAPID_PUBLIC_KEY && process.env.VAPID_PRIVATE_KEY) {
        webPush.setVapidDetails(
            process.env.VAPID_SUBJECT || 'mailto:admin@youtube2podcast.local',
            process.env.VAPID_PUBLIC_KEY,
            process.env.VAPID_PRIVATE_KEY
        );
        configured = true;
    }
}

async function sendNotification(userId, title, body, options = {}) {
    configure();
    // ... lÃ³gica de envÃ­o
}

module.exports = { configure, sendNotification };
```

---

### P2-RAM-06: ConversiÃ³n WAV innecesaria consume RAM

| Campo | Valor |
|-------|-------|
| **Archivo** | `scripts/process_translation.py:148-151` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¡ Medio (30 min) |

**Problema:**  
`AudioSegment.from_mp3()` carga TODO el audio en RAM para convertir a WAV.

**CÃ³digo actual:**
```python
from pydub import AudioSegment
audio = AudioSegment.from_mp3(temp_mp3)  # CARGA TODO EN RAM
audio.export(output_path, format="wav")
```

**Impacto:**
- Audio de 1 hora = ~600MB RAM
- Pico de memoria durante conversiÃ³n

**SoluciÃ³n A: Mantener MP3 (recomendado)**
```python
# edge-tts ya genera MP3, no convertir
await communicate.save(output_path)  # Guardar directamente como MP3

# Cambiar extensiÃ³n en translation_service.js
const outputFileName = `${episode.youtube_id}_es.mp3`;  // MP3 en vez de WAV
```

**SoluciÃ³n B: Usar FFmpeg streaming**
```python
import subprocess

# Convertir sin cargar en memoria
subprocess.run([
    'ffmpeg', '-i', temp_mp3, 
    '-acodec', 'pcm_s16le',
    '-ar', '44100',
    '-y', output_path
], check=True, capture_output=True)
```

---

### P2-RAM-07: Prepared statements no cacheados

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/db.js` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¡ Medio (1 hora) |

**Problema:**  
`db.prepare()` se llama cada vez que se ejecuta una funciÃ³n.

**SoluciÃ³n: Cache de statements**
```javascript
// Statements cacheados (al inicio del mÃ³dulo)
const statements = {
    getEpisodeById: db.prepare('SELECT * FROM episodes WHERE id = ?'),
    getEpisodeByYoutubeId: db.prepare('SELECT * FROM episodes WHERE youtube_id = ?'),
    getUserByUsername: db.prepare('SELECT * FROM users WHERE username = ?'),
    // ... mÃ¡s statements
};

module.exports = {
    getEpisodeById: (id) => statements.getEpisodeById.get(id),
    getEpisodeByYoutubeId: (youtubeId) => statements.getEpisodeByYoutubeId.get(youtubeId),
    // ...
};
```

---

### P3-RAM-08: SUPPORTED_LANGUAGES duplicado

| Campo | Valor |
|-------|-------|
| **Archivos** | `src/transcription_service.js:33-57`, `scripts/process_transcription.py:24-55` |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¡ Medio (30 min) |

**SoluciÃ³n: Archivo JSON compartido**
```json
// config/languages.json
{
    "en": "English",
    "es": "EspaÃ±ol",
    "fr": "FranÃ§ais"
    // ...
}
```

---

### P3-RAM-09: Sessions sin TTL de limpieza

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/index.js:41-50` |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¢ Bajo (5 min) |

**SoluciÃ³n:**
```javascript
app.use(session({
    store: new SQLiteStore({
        db: 'sessions.db',
        dir: path.join(__dirname, '../data'),
        // Agregar limpieza automÃ¡tica
        cleanupInterval: 900000  // 15 minutos
    }),
    // ...
}));
```

---

## ğŸŸ  3. I/O Y ACCESO A DISCO/RED

### P1-IO-01: fs.existsSync() usado excesivamente

| Campo | Valor |
|-------|-------|
| **Archivos** | MÃºltiples (`src/downloader.js`, `src/index.js`, etc.) |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸŸ¡ Medio (2 horas) |

**Ubicaciones encontradas:**
- `src/downloader.js:71, 222`
- `src/index.js:247, 262, 421, 451`
- `src/transcription_service.js:193, 270, 378`
- `src/translation_service.js:165, 248, 368`

**Problema:**
1. `existsSync()` es sÃ­ncrono y bloquea
2. Es un anti-pattern TOCTTOU (Time-of-check to time-of-use)

**PatrÃ³n correcto:**
```javascript
// ANTES (anti-pattern)
if (fs.existsSync(filePath)) {
    fs.unlinkSync(filePath);
}

// DESPUÃ‰S (correcto)
try {
    await fs.promises.unlink(filePath);
} catch (err) {
    if (err.code !== 'ENOENT') throw err;
    // ENOENT = archivo no existe, ignorar
}

// ANTES (verificar antes de leer)
if (fs.existsSync(filePath)) {
    const content = fs.readFileSync(filePath);
}

// DESPUÃ‰S
try {
    const content = await fs.promises.readFile(filePath);
} catch (err) {
    if (err.code === 'ENOENT') {
        // Manejar archivo no existente
    } else {
        throw err;
    }
}
```

---

### P1-IO-02: Archivos de audio sin Range request optimization

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/index.js:36` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸŸ¢ Bajo (5 min) |

**CÃ³digo actual:**
```javascript
app.use('/downloads', express.static(path.join(__dirname, '../downloads')));
```

**SoluciÃ³n: Agregar opciones de optimizaciÃ³n**
```javascript
app.use('/downloads', express.static(path.join(__dirname, '../downloads'), {
    acceptRanges: true,      // Permitir seeking en audio
    maxAge: '1d',            // Cache 1 dÃ­a
    etag: true,              // ETags para validaciÃ³n
    lastModified: true,
    immutable: false         // Los archivos pueden cambiar
}));
```

---

### P2-IO-03: fs.readdirSync() en cleanupTempFiles()

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/downloader.js:51` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (10 min) |

**SoluciÃ³n:**
```javascript
async function cleanupTempFiles(videoId) {
    try {
        const files = await fs.promises.readdir(TEMP_DIR);
        const deletePromises = files
            .filter(f => f.startsWith(videoId))
            .map(f => fs.promises.unlink(path.join(TEMP_DIR, f)).catch(() => {}));
        
        await Promise.all(deletePromises);
    } catch (e) {
        logError('Error cleaning temp files:', e);
    }
}
```

---

### P2-IO-04: unlinkSync() en loops

| Campo | Valor |
|-------|-------|
| **Archivos** | `src/index.js:249,269`, `src/downloader.js:56,73` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (15 min) |

**CÃ³digo actual:**
```javascript
tempFiles.forEach(file => {
    if (file.startsWith(episode.youtube_id)) {
        fs.unlinkSync(tempFilePath);  // BLOQUEA
    }
});
```

**SoluciÃ³n: Batch async deletes**
```javascript
const filesToDelete = tempFiles
    .filter(file => file.startsWith(episode.youtube_id))
    .map(file => path.join(tempDir, file));

await Promise.all(
    filesToDelete.map(f => fs.promises.unlink(f).catch(() => {}))
);
```

---

### P2-IO-05: Thumbnail de YouTube no cacheado localmente

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/downloader.js` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¡ Medio (1 hora) |

**Problema:**  
Cada carga de pÃ¡gina hace request a YouTube para thumbnails.

**SoluciÃ³n: Descargar thumbnail localmente**
```javascript
// En performDownload(), despuÃ©s de descargar el audio
async function downloadThumbnail(videoId, thumbnailUrl) {
    const thumbnailPath = path.join(DOWNLOADS_DIR, `${videoId}_thumb.jpg`);
    
    try {
        const response = await fetch(thumbnailUrl);
        const buffer = await response.buffer();
        await fs.promises.writeFile(thumbnailPath, buffer);
        return `${videoId}_thumb.jpg`;
    } catch (err) {
        logError('Error downloading thumbnail:', err);
        return null;  // Fallback a URL externa
    }
}
```

---

### P2-IO-06: No hay compresiÃ³n de responses HTTP

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/index.js` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (5 min) |

**SoluciÃ³n:**
```javascript
const compression = require('compression');

// Agregar antes de otros middlewares
app.use(compression({
    level: 6,  // Balance entre CPU y compresiÃ³n
    threshold: 1024,  // Solo comprimir > 1KB
    filter: (req, res) => {
        // No comprimir SSE
        if (req.headers.accept === 'text/event-stream') {
            return false;
        }
        return compression.filter(req, res);
    }
}));
```

**Agregar a package.json:**
```json
"dependencies": {
    "compression": "^1.7.4",
    // ...
}
```

---

### P3-IO-07: MÃºltiples writes a DB para un episodio

| Campo | Valor |
|-------|-------|
| **Archivos** | `src/downloader.js:122`, `src/db.js:161-166` |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¢ Bajo (15 min) |

**SoluciÃ³n: Transacciones cuando sea apropiado**
```javascript
const insertAndUpdate = db.transaction((episode) => {
    const result = db.prepare(`
        INSERT INTO episodes (youtube_id, title, file_path, original_url, user_id, status, thumbnail_url)
        VALUES (@youtube_id, @title, @file_path, @original_url, @user_id, @status, @thumbnail_url)
    `).run(episode);
    
    return result;
});
```

---

### P3-IO-08: PDF generation no streamed

| Campo | Valor |
|-------|-------|
| **Archivo** | `scripts/process_transcription.py:183` |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¡ Medio (30 min) |

**Nota:** fpdf2 no soporta streaming nativo. Para transcripciones muy largas, considerar:
- Dividir en mÃºltiples PDFs
- Usar reportlab que soporta streaming

---

## ğŸ”µ 4. USO DE ANCHO DE BANDA

### P1-BW-01: Bootstrap Icons bundle completo

| Campo | Valor |
|-------|-------|
| **Archivos** | `src/index.js:38`, `views/index.ejs:9` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸŸ¡ Medio (2 horas) |

**Problema:**  
Se sirve TODO el paquete de bootstrap-icons (~1.5MB fonts+CSS) cuando solo se usan ~20 iconos.

**Iconos usados en el proyecto:**
```
bi-bell, bi-bell-fill, bi-moon-fill, bi-sun-fill, bi-person-walking,
bi-stopwatch, bi-lightbulb, bi-x-lg, bi-translate, bi-file-earmark-pdf-fill,
bi-file-earmark-text, bi-box-arrow-up-right, bi-download, bi-trash3,
bi-arrow-repeat, bi-exclamation-circle, bi-info-circle, bi-x-circle
```

**SoluciÃ³n A: SVG Inline (recomendado)**
```javascript
// Crear archivo con solo los iconos necesarios
// public/icons/icons.js
const icons = {
    bell: '<svg...>',
    'bell-fill': '<svg...>',
    // ...
};

// Usar en templates
<span class="icon"><%= icons.bell %></span>
```

**SoluciÃ³n B: Subset de fuente**
```bash
# Usar fonttools para crear subset
pip install fonttools
pyftsubset bootstrap-icons.woff2 \
    --unicodes="U+F135,U+F136,..." \
    --output-file="icons-subset.woff2"
```

---

### P2-BW-02: CSS sin purge en producciÃ³n

| Campo | Valor |
|-------|-------|
| **Archivo** | `tailwind.config.js` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (10 min) |

**Verificar configuraciÃ³n:**
```javascript
// tailwind.config.js
module.exports = {
    content: [
        './views/**/*.ejs',
        './public/js/**/*.js'
    ],
    // ...
}
```

**Build para producciÃ³n:**
```bash
NODE_ENV=production npm run build:css
```

---

### P2-BW-03: Sin cache headers para assets estÃ¡ticos

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/index.js:35-38` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (5 min) |

**SoluciÃ³n:**
```javascript
// Assets estÃ¡ticos con cache largo
app.use(express.static(path.join(__dirname, '../public'), {
    maxAge: '7d',
    etag: true,
    lastModified: true
}));

// Vendor con cache muy largo (versionado)
app.use('/vendor', express.static(path.join(__dirname, '../node_modules'), {
    maxAge: '30d',
    immutable: true
}));
```

---

### P2-BW-04: Payloads JSON sin minimizaciÃ³n

| Campo | Valor |
|-------|-------|
| **Archivos** | Endpoints API en `src/index.js` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¡ Medio (1 hora) |

**Ejemplo de optimizaciÃ³n:**
```javascript
// ANTES - devuelve todo
getEpisodesByIds: (ids) => {
    return db.prepare(`SELECT * FROM episodes WHERE id IN (...)`).all(...ids);
}

// DESPUÃ‰S - solo campos necesarios
getEpisodesByIds: (ids) => {
    return db.prepare(`
        SELECT id, youtube_id, status, translation_status, transcription_status
        FROM episodes WHERE id IN (...)
    `).all(...ids);
}
```

---

### P3-BW-05: Service Worker cache muy limitado

| Campo | Valor |
|-------|-------|
| **Archivo** | `public/sw.js:2-6` |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¢ Bajo (10 min) |

**CÃ³digo actual:**
```javascript
const STATIC_ASSETS = [
    '/css/styles.css',
    '/css/custom.css',
    '/icons/logo.png'
];
```

**SoluciÃ³n:**
```javascript
const STATIC_ASSETS = [
    '/css/styles.css',
    '/css/custom.css',
    '/icons/logo.png',
    '/vendor/bi/font/bootstrap-icons.css',
    '/manifest.json',
    '/'  // PÃ¡gina principal
];
```

---

### P3-BW-06: SSE sin compresiÃ³n

| Campo | Valor |
|-------|-------|
| **Archivo** | `src/index.js:98-102` |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¡ Medio |

**Nota:** SSE generalmente no se comprime porque los mensajes son pequeÃ±os y frecuentes. La sobrecarga de compresiÃ³n/descompresiÃ³n no vale la pena.

---

## ğŸ“ 5. OPTIMIZACIONES ESPECÃFICAS PARA RASPBERRY PI 4

### P1-RPI-01: PyTorch ocupa ~1.5GB RAM

| Campo | Valor |
|-------|-------|
| **Archivo** | `requirements.txt:26-27` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸ”´ Alto (1 dÃ­a) |

**Problema:**  
PyTorch para ARM es enorme (~500MB descarga, ~1.5GB en memoria).

**Desglose de dependencias:**
```
torch (CPU): ~500MB en disco, ~1.5GB RAM
â”œâ”€â”€ faster-whisper lo usa para inference
â””â”€â”€ transformers lo usa para traducciÃ³n
```

**SoluciÃ³n: Migrar a ONNX Runtime**

faster-whisper soporta CTranslate2 que puede usar ONNX:

```txt
# requirements.txt optimizado
# Reemplazar torch por onnxruntime
onnxruntime>=1.16.0

# faster-whisper con backend CTranslate2 (sin torch)
faster-whisper>=1.0.0

# transformers con ONNX
optimum[onnxruntime]>=1.14.0
```

**CÃ³digo actualizado:**
```python
# Para transcripciÃ³n (ya funciona sin cambios, faster-whisper usa CT2)
from faster_whisper import WhisperModel
model = WhisperModel("tiny", device="cpu", compute_type="int8")

# Para traducciÃ³n con ONNX
from optimum.onnxruntime import ORTModelForSeq2SeqLM
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-es")
model = ORTModelForSeq2SeqLM.from_pretrained(
    "Helsinki-NLP/opus-mt-en-es",
    export=True  # Convierte a ONNX automÃ¡ticamente
)
```

---

### P1-RPI-02: Procesos Python no aprovechan los 4 cores

| Campo | Valor |
|-------|-------|
| **Archivos** | `scripts/*.py` |
| **Severidad** | ğŸ”´ CrÃ­tica |
| **Esfuerzo** | ğŸŸ¡ Medio (4 horas) |

**Problema:**  
- Python GIL limita paralelismo en un solo proceso
- Los modelos de IA son mayormente single-threaded en Python

**SoluciÃ³n A: Afinity de CPU explÃ­cita**
```python
import os

# Al inicio del script
os.sched_setaffinity(0, {0, 1, 2, 3})  # Usar todos los cores

# Ya configurado pero verificar que funcione
os.environ["OMP_NUM_THREADS"] = "4"
os.environ["MKL_NUM_THREADS"] = "4"
```

**SoluciÃ³n B: Pipeline paralelo para audios largos**
```python
from concurrent.futures import ThreadPoolExecutor

def process_audio_parallel(audio_path):
    # Dividir audio en chunks
    chunks = split_audio(audio_path, chunk_duration=60)  # 1 min cada uno
    
    # Procesar en paralelo (limitado por GIL pero ayuda en I/O)
    with ThreadPoolExecutor(max_workers=2) as executor:
        results = list(executor.map(transcribe_chunk, chunks))
    
    return merge_results(results)
```

---

### P2-RPI-03: Modelo Whisper "tiny" vs "tiny.en"

| Campo | Valor |
|-------|-------|
| **Archivos** | `scripts/process_translation.py:42` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (5 min) |

**Problema:**  
Para traducciÃ³n ENâ†’ES, el audio siempre es en inglÃ©s. El modelo "tiny" es multilingÃ¼e y mÃ¡s lento.

**Benchmarks aproximados en RPi4:**

| Modelo | TamaÃ±o | Velocidad (1 min audio) |
|--------|--------|-------------------------|
| tiny | 75MB | ~15 seg |
| tiny.en | 75MB | ~10 seg |

**SoluciÃ³n:**
```python
# En process_translation.py (siempre inglÃ©s)
model = WhisperModel("tiny.en", device="cpu", compute_type="int8")

# En process_transcription.py (mantener tiny para multilingÃ¼e)
# Pero si el idioma es inglÃ©s:
if language == "en":
    model = WhisperModel("tiny.en", device="cpu", compute_type="int8")
else:
    model = WhisperModel("tiny", device="cpu", compute_type="int8")
```

---

### P2-RPI-04: beam_size=5 es excesivo para ARM

| Campo | Valor |
|-------|-------|
| **Archivos** | `scripts/process_transcription.py:88`, `scripts/process_translation.py:51` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¢ Bajo (2 min) |

**Problema:**  
`beam_size=5` usa mÃ¡s RAM y CPU. Para RPi4, `beam_size=1` (greedy) es ~3x mÃ¡s rÃ¡pido.

**Benchmarks:**

| beam_size | Velocidad | Calidad |
|-----------|-----------|---------|
| 5 | 1x | 100% |
| 3 | 1.5x | 98% |
| 1 | 3x | 95% |

**SoluciÃ³n:**
```python
segments, info = model.transcribe(
    audio_path,
    language=language,
    beam_size=1,  # Greedy decoding - mucho mÃ¡s rÃ¡pido
    best_of=1,    # Sin sampling adicional
    vad_filter=True,
    vad_parameters=dict(min_silence_duration_ms=500)
)
```

---

### P2-RPI-05: Modelo de traducciÃ³n podrÃ­a ser mÃ¡s ligero

| Campo | Valor |
|-------|-------|
| **Archivo** | `scripts/process_translation.py:84` |
| **Severidad** | ğŸŸ¡ Importante |
| **Esfuerzo** | ğŸŸ¡ Medio (4 horas) |

**Alternativas mÃ¡s ligeras:**

| Modelo | TamaÃ±o | Calidad |
|--------|--------|---------|
| Helsinki-NLP/opus-mt-en-es | ~300MB | Excelente |
| Helsinki-NLP/opus-mt-tc-big-en-es | ~200MB | Muy buena |
| ct2-converted model | ~100MB | Buena |

**SoluciÃ³n: Usar CTranslate2 directamente**
```python
import ctranslate2
import sentencepiece as spm

# Modelo pre-convertido (mÃ¡s rÃ¡pido)
translator = ctranslate2.Translator(
    "models/opus-mt-en-es-ct2",
    device="cpu",
    compute_type="int8"
)

# Tokenizer
sp = spm.SentencePieceProcessor("models/source.spm")

def translate(text):
    tokens = sp.encode(text, out_type=str)
    results = translator.translate_batch([tokens])
    return sp.decode(results[0].hypotheses[0])
```

**Script para convertir modelo:**
```bash
ct2-opus-mt-converter --model Helsinki-NLP/opus-mt-en-es \
    --output_dir models/opus-mt-en-es-ct2 \
    --quantization int8
```

---

### P3-RPI-06: ConfiguraciÃ³n de swappiness

| Campo | Valor |
|-------|-------|
| **Contexto** | Sistema operativo |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¢ Bajo (2 min) |

**Problema:**  
Con 8GB RAM, el sistema puede swapear innecesariamente afectando performance.

**SoluciÃ³n:**
```bash
# Verificar valor actual
cat /proc/sys/vm/swappiness  # Default: 60

# Reducir a 10 (menos swap)
echo 10 | sudo tee /proc/sys/vm/swappiness

# Hacer permanente
echo "vm.swappiness=10" | sudo tee -a /etc/sysctl.conf
```

---

### P3-RPI-07: zram para compresiÃ³n de RAM

| Campo | Valor |
|-------|-------|
| **Contexto** | Sistema operativo |
| **Severidad** | ğŸŸ¢ Opcional |
| **Esfuerzo** | ğŸŸ¢ Bajo (5 min) |

**Beneficio:**  
zram comprime RAM en vez de swapear a SD/disco, ~2-3x mÃ¡s capacidad efectiva.

**InstalaciÃ³n:**
```bash
sudo apt install zram-tools

# Configurar
sudo nano /etc/default/zramswap
# ALGO=lz4
# PERCENT=50

# Reiniciar servicio
sudo systemctl restart zramswap
```

---

## ğŸ“Š Matriz de PriorizaciÃ³n

### Por Impacto vs Esfuerzo

```
                    IMPACTO
                Alto â”‚ Medio â”‚ Bajo
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    Alto â”‚ P1-CPU-02â”‚       â”‚          â”‚
         â”‚ P1-RAM-01â”‚       â”‚          â”‚
         â”‚ P1-RPI-01â”‚       â”‚          â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Esfuerzo â”‚ P1-RPI-02â”‚P2-*   â”‚          â”‚
   Medio â”‚ P1-BW-01 â”‚       â”‚          â”‚
         â”‚ P1-IO-01 â”‚       â”‚          â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    Bajo â”‚ P1-CPU-01â”‚P2-IO-06â”‚ P3-*    â”‚
         â”‚ P1-CPU-04â”‚P2-BW-03â”‚          â”‚
         â”‚ P2-RPI-04â”‚       â”‚          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Quick Wins (Alto Impacto, Bajo Esfuerzo)

| ID | DescripciÃ³n | Tiempo |
|----|-------------|--------|
| P1-CPU-01 | bcrypt async | 5 min |
| P2-IO-06 | Agregar compression() | 5 min |
| P2-BW-03 | Cache headers | 5 min |
| P2-RPI-04 | beam_size=1 | 2 min |
| P1-CPU-04 | Hashes pre-calculados | 10 min |
| P2-RPI-03 | tiny.en para inglÃ©s | 5 min |

---

## ğŸ¯ Plan de AcciÃ³n Recomendado

### Fase 1: Quick Wins (1-2 horas)

```bash
# Checklist
[ ] Cambiar bcrypt.compareSync a async
[ ] Agregar compression() middleware
[ ] Configurar cache headers en static
[ ] Reducir beam_size a 1 en Whisper
[ ] Usar tiny.en para traducciÃ³n
[ ] Hashes pre-calculados para seed users
```

**Impacto esperado:**
- Login 3x mÃ¡s rÃ¡pido
- Responses HTTP 60-70% mÃ¡s pequeÃ±os
- TranscripciÃ³n 2-3x mÃ¡s rÃ¡pida

### Fase 2: OptimizaciÃ³n Media (1-2 dÃ­as)

```bash
# Checklist
[ ] Implementar worker Python persistente
[ ] Migrar de torch a ONNX runtime
[ ] Crear subset de Bootstrap Icons
[ ] Agregar paginaciÃ³n a getEpisodes()
[ ] Consolidar EventEmitters
[ ] Migrar fs sync a async
```

**Impacto esperado:**
- ReducciÃ³n de RAM de 3GB a 1GB por proceso
- Tiempo de inicio de tareas de 30s a 2s
- Menor uso de bandwidth

### Fase 3: Refactoring Mayor (1 semana)

```bash
# Checklist
[ ] Implementar cola de jobs con prioridades
[ ] Convertir modelo de traducciÃ³n a CTranslate2
[ ] Cachear thumbnails localmente
[ ] Implementar streaming de audio
[ ] Tests de carga en RPi4
```

**Impacto esperado:**
- Sistema estable bajo carga
- Uso eficiente de los 4 cores
- Menor latencia en todas las operaciones

---

## ğŸ“ˆ MÃ©tricas de Ã‰xito

### Antes de optimizar (baseline)

| MÃ©trica | Valor Actual |
|---------|--------------|
| Tiempo de login | ~300ms |
| Tiempo inicio transcripciÃ³n | ~30s |
| RAM por proceso Python | ~2GB |
| TamaÃ±o CSS | ~500KB |
| TamaÃ±o iconos | ~1.5MB |

### Objetivos post-optimizaciÃ³n

| MÃ©trica | Objetivo |
|---------|----------|
| Tiempo de login | <50ms |
| Tiempo inicio transcripciÃ³n | <5s |
| RAM por proceso Python | <800MB |
| TamaÃ±o CSS | <50KB |
| TamaÃ±o iconos | <100KB |

---

## ğŸ”§ Scripts de Benchmark

### Test de CPU

```bash
#!/bin/bash
# benchmark_cpu.sh

echo "=== Benchmark de TranscripciÃ³n ==="
time python3 scripts/process_transcription.py \
    downloads/test.mp3 \
    /tmp/test_transcript.pdf \
    --language en

echo ""
echo "=== Benchmark de TraducciÃ³n ==="
time python3 scripts/process_translation.py \
    downloads/test.mp3 \
    /tmp/test_translation.wav
```

### Test de Memoria

```bash
#!/bin/bash
# benchmark_memory.sh

echo "=== Uso de memoria durante transcripciÃ³n ==="
/usr/bin/time -v python3 scripts/process_transcription.py \
    downloads/test.mp3 \
    /tmp/test_transcript.pdf \
    --language en 2>&1 | grep "Maximum resident set size"
```

### Test de I/O

```bash
#!/bin/bash
# benchmark_io.sh

echo "=== Test de lectura/escritura ==="
dd if=/dev/zero of=/tmp/testfile bs=1M count=100 2>&1 | tail -1
dd if=/tmp/testfile of=/dev/null bs=1M 2>&1 | tail -1
rm /tmp/testfile
```

---

## ğŸ“š Referencias

- [faster-whisper optimization](https://github.com/guillaumekln/faster-whisper)
- [CTranslate2 for ARM](https://github.com/OpenNMT/CTranslate2)
- [Node.js best practices](https://github.com/goldbergyoni/nodebestpractices)
- [Raspberry Pi performance tuning](https://www.raspberrypi.com/documentation/computers/config_txt.html)
- [ONNX Runtime for ARM](https://onnxruntime.ai/docs/execution-providers/community-maintained/ARM.html)

---

*Reporte generado para Youtube2Podcast v1.5.0*  
*Hardware objetivo: Raspberry Pi 4 (ARMv8, 4 cores, 8GB RAM)*

